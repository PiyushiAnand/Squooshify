{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVkQpuaDh0hX"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHE6Mh0lZeZ6",
        "outputId": "7070f90e-5570-4753-f060-235ccb68cffc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.fftpack import dct, idct\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import heapq\n",
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "from bitstring import BitStream\n",
        "import io\n",
        "import gzip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSJEFQgjh7Rz"
      },
      "source": [
        "# Function to compute DCT and inverse DCT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1sAAsfVic01c"
      },
      "outputs": [],
      "source": [
        "# DCT and inverse DCT for 8x8 blocks\n",
        "def compute_dct(block):\n",
        "    return dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
        "\n",
        "def compute_idct(block):\n",
        "    return idct(idct(block.T, norm='ortho').T, norm='ortho')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ILHYNxoiCvP"
      },
      "source": [
        "# Define the Quantization Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UQ9vdUfzc_PZ"
      },
      "outputs": [],
      "source": [
        "# Standard JPEG quantization matrix\n",
        "quantization_matrix = np.array([\n",
        "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwBPBjB2iJq4"
      },
      "source": [
        "# Load the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ajvXZgY-dCVa"
      },
      "outputs": [],
      "source": [
        "def load_image(filepath):\n",
        "    image = Image.open(filepath).convert('L')   #read the image as grayscale\n",
        "    return np.array(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBBU-ddFiL_l"
      },
      "source": [
        "# Function for Huffman encoding and decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hQBLJVsjdE3X"
      },
      "outputs": [],
      "source": [
        "# Huffman Tree generation\n",
        "def build_huffman_tree(data):\n",
        "    frequency = Counter(data)\n",
        "    heap = [[weight, [symbol, \"\"]] for symbol, weight in frequency.items()]\n",
        "    heapq.heapify(heap)\n",
        "    while len(heap) > 1:\n",
        "        lo = heapq.heappop(heap)\n",
        "        hi = heapq.heappop(heap)\n",
        "        for pair in lo[1:]:\n",
        "            pair[1] = '0' + pair[1]\n",
        "        for pair in hi[1:]:\n",
        "            pair[1] = '1' + pair[1]\n",
        "        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
        "    return {symbol: code for symbol, code in heapq.heappop(heap)[1:]}\n",
        "\n",
        "def huffman_encode(data, huffman_table):\n",
        "    return ''.join(huffman_table[val] for val in data)\n",
        "\n",
        "def huffman_decode(encoded_data, huffman_table):\n",
        "    inverse_table = {code: symbol for symbol, code in huffman_table.items()}\n",
        "    decoded_data, current_code = [], \"\"\n",
        "    for bit in encoded_data:\n",
        "        current_code += bit\n",
        "        if current_code in inverse_table:\n",
        "            decoded_data.append(inverse_table[current_code])\n",
        "            current_code = \"\"\n",
        "    return decoded_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BOu40f5iVcn"
      },
      "source": [
        "# Functions for Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7R2HVGPddLpg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def quantize_block(dct_block, quant_matrix, quality_factor):\n",
        "    '''Quantize the DCT block'''\n",
        "    # Ensure quality_factor is within valid bounds\n",
        "    quality_factor = max(1, min(100, quality_factor))\n",
        "\n",
        "    #find the scale acc to quality factor \n",
        "    if quality_factor < 50:\n",
        "      scale = 5000 / quality_factor\n",
        "    else:\n",
        "      scale = 200 - 2 * quality_factor\n",
        "\n",
        "    #find the adjusted matrx\n",
        "    adjusted_matrix = np.floor((quantization_matrix * scale + 50) / 100)\n",
        "    adjusted_matrix[adjusted_matrix == 0] = 1\n",
        "    # Quantize the DCT block\n",
        "    \n",
        "    quantized_block = np.round(dct_block / adjusted_matrix).astype(int)\n",
        "    # print(adjusted_matrix)\n",
        "    return quantized_block, adjusted_matrix\n",
        "\n",
        "def dequantize_block(quantized_block, adjusted_matrix):\n",
        "    '''dequantize the block'''\n",
        "    return (quantized_block * adjusted_matrix).astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypK_FwWHibNT"
      },
      "source": [
        "# ZigZag order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gCkifKDkdYmz"
      },
      "outputs": [],
      "source": [
        "def zigzag_order(block):\n",
        "    '''get zigzag order of the block'''\n",
        "    rows, cols = block.shape\n",
        "    solution = [[] for i in range(rows + cols - 1)]\n",
        "\n",
        "    for row in range(rows):\n",
        "        for col in range(cols):\n",
        "            sum = row + col\n",
        "            if(sum % 2 == 0):\n",
        "                #add at beginning\n",
        "                solution[sum].insert(0, block[row][col])\n",
        "            else:\n",
        "                #add at end of the list\n",
        "                solution[sum].append(block[row][col])\n",
        "\n",
        "    return np.array([item for sublist in solution for item in sublist])\n",
        "def inverse_zigzag_order(zigzag_values, block_size=8):\n",
        "    '''get inverse zigzag order'''\n",
        "    matrix = np.zeros((block_size, block_size), dtype=int)\n",
        "    index = 0\n",
        "\n",
        "    for i in range(block_size + block_size - 1):\n",
        "        if i % 2 == 0:  # Even diagonal (up-right)\n",
        "            # Moving up-right with decrementing row and incrementing column\n",
        "            for j in range(min(i + 1, block_size)):\n",
        "                row = i - j\n",
        "                col = j\n",
        "                if row >= 0 and row < block_size and col >= 0 and col < block_size:  # Check matrix boundaries\n",
        "                    matrix[row, col] = zigzag_values[index]\n",
        "                    index += 1\n",
        "        else:  # Odd diagonal (down-left)\n",
        "            # Moving down-left with incrementing row and decrementing column\n",
        "            for j in range(min(i + 1, block_size)):\n",
        "                col = i - j\n",
        "                row = j\n",
        "                if row >= 0 and row < block_size and col >= 0 and col < block_size:\n",
        "                    matrix[row, col] = zigzag_values[index]\n",
        "                    index += 1\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIi0Zocbieab"
      },
      "source": [
        "# Run Length Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IbKrcuQgXPWP"
      },
      "outputs": [],
      "source": [
        "def run_length_encoding(zigzag_values,huffman_table):\n",
        "    encoded_values = []\n",
        "    run_length = 0\n",
        "\n",
        "    for value in zigzag_values:\n",
        "        if value == 0:\n",
        "            run_length += 1\n",
        "        else:\n",
        "            encoded_values.append((np.uint8(run_length),huffman_table[value]))  # Store run-length, size, and value\n",
        "            run_length = 0  # Reset run-length\n",
        "\n",
        "    # Store trailing zeros count in the EOB marker:\n",
        "    encoded_values.append((np.uint8(run_length),-1))  # EOB with trailing zeros count\n",
        "    # encoded_values.append((0, 0, 'EOB'))\n",
        "    return encoded_values\n",
        "\n",
        "def run_length_decoding(encoded_values):\n",
        "    decoded_values = []\n",
        "    trailing_zeros_count = 0  # Initialize trailing zeros count\n",
        "\n",
        "    for run_length , value in encoded_values:\n",
        "        if value == -1:  # Check for EOB marker\n",
        "            trailing_zeros_count = value  # Get trailing zeros count from EOB\n",
        "            break  # Stop decoding at the EOB marker\n",
        "        else:\n",
        "            decoded_values.extend([0] * run_length)  # Add zeros for the run-length\n",
        "            decoded_values.append(value)  # Append the actual value\n",
        "\n",
        "    # Add trailing zeros (if any) after decoding:\n",
        "    decoded_values.extend([0] * trailing_zeros_count)\n",
        "\n",
        "    return decoded_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZXSnSnD4x0p"
      },
      "source": [
        "# Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZxCmVgvE4wzB"
      },
      "outputs": [],
      "source": [
        "def pad_image(image, block_size=8):\n",
        "    \"\"\"Pad the image to make its dimensions a multiple of block_size.\"\"\"\n",
        "    height, width = image.shape\n",
        "    pad_height = (block_size - (height % block_size)) % block_size\n",
        "    pad_width = (block_size - (width % block_size)) % block_size\n",
        "    padded_image = np.pad(image, ((0, pad_height), (0, pad_width)), mode='constant')\n",
        "    return padded_image, height, width"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compress Image JPEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compress_image(filepath, quality_factor):\n",
        "    image = load_image(filepath)\n",
        "    height, width = image.shape\n",
        "    compressed_data = []\n",
        "    dc_diff_values = []\n",
        "    ac_values = []\n",
        "\n",
        "    adjusted_matrix = None\n",
        "    quantized_blocks = []\n",
        "    dct_blocks = []\n",
        "\n",
        "    #pad the image so that both row and column are nearest multiple 8\n",
        "    padded_image, original_height, original_width = pad_image(image, 8)\n",
        "    padded_height, padded_width = padded_image.shape\n",
        "    \n",
        "    # Divide into 8x8 blocks, apply DCT and quantize\n",
        "    previous_dc = 0\n",
        "    #store the orignal size of image as well\n",
        "    for i in range(0, padded_height, 8):\n",
        "        for j in range(0, padded_width, 8):\n",
        "            dct_blocks.append(padded_image[i:i+8, j:j+8])\n",
        "            block = padded_image[i:i+8, j:j+8]\n",
        "            dct_block = compute_dct(block)\n",
        "   \n",
        "            quantized_block, adjusted_matrix = quantize_block(dct_block, quantization_matrix, quality_factor)\n",
        "            quantized_blocks.append(quantized_block)\n",
        "\n",
        "            # DC and AC separation\n",
        "            dc_diff = quantized_block[0, 0] - previous_dc\n",
        "            previous_dc = quantized_block[0, 0]\n",
        "            dc_diff_values.append(dc_diff)\n",
        "            ac_values.extend(zigzag_order(quantized_block)[1:])\n",
        "\n",
        "    # Build Huffman trees\n",
        "    dc_huffman_table = build_huffman_tree(dc_diff_values)\n",
        "    ac_huffman_table = build_huffman_tree([val for val in ac_values if val != 0])\n",
        "   \n",
        "    # Compress each block\n",
        "    previous_dc = 0\n",
        "    for i in range(0, padded_height, 8):\n",
        "        for j in range(0, padded_width, 8):\n",
        "            block = padded_image[i:i+8, j:j+8]\n",
        "            dct_block = compute_dct(block)\n",
        "            quantized_block, adjusted_matrix = quantize_block(dct_block, quantization_matrix, quality_factor)\n",
        "\n",
        "            # Encode DC\n",
        "            dc_diff = quantized_block[0, 0] - previous_dc\n",
        "            previous_dc = quantized_block[0, 0]\n",
        "            dc_encoded = dc_huffman_table[dc_diff]\n",
        "\n",
        "            # Encode AC with run-length, size, and Huffman code\n",
        "            zigzag_ac = zigzag_order(quantized_block)[1:]\n",
        "            ac_encoded = run_length_encoding(zigzag_ac,ac_huffman_table)\n",
        "            compressed_data.append((dc_encoded, ac_encoded))\n",
        "\n",
        "    header = {\n",
        "        'file_size': (height, width),\n",
        "        'dc_huffman_table': dc_huffman_table,\n",
        "        'ac_huffman_table': ac_huffman_table,\n",
        "        'adjusted_matrix': adjusted_matrix\n",
        "    }\n",
        "\n",
        "    compressed_stream = BytesIO()\n",
        "    with gzip.GzipFile(fileobj=compressed_stream, mode='wb') as f:\n",
        "        pickle.dump(header, f)\n",
        "        pickle.dump(compressed_data, f)\n",
        "\n",
        "    return compressed_stream.getvalue(), dc_huffman_table, ac_huffman_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decompress Image JPEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decompress_image(compressed_data):\n",
        "\n",
        "    compressed_stream = BytesIO(compressed_data)\n",
        "\n",
        "    # Open the gzip file in read mode\n",
        "    with gzip.GzipFile(fileobj=compressed_stream, mode='rb') as f:\n",
        "        # Load the header and compressed data from the stream\n",
        "        header = pickle.load(f)\n",
        "        compressed_blocks = pickle.load(f)\n",
        "    \n",
        "    # Extract header information\n",
        "    original_height, original_width = header['file_size']  # Extract original dimensions\n",
        "    dc_huffman_table = header['dc_huffman_table']\n",
        "    ac_huffman_table = header['ac_huffman_table']\n",
        "    adjusted_matrix = header['adjusted_matrix']\n",
        "    \n",
        "    # Initialize decompressed image with padded size\n",
        "    blocks_per_row = int(np.sqrt(len(compressed_blocks)))  \n",
        "    block_size = 8\n",
        "    decompressed_image = np.zeros((original_height, original_width), dtype=np.uint8)\n",
        "    decompressed_image = pad_image(decompressed_image, block_size)[0]\n",
        "    padded_height, padded_width = decompressed_image.shape\n",
        "\n",
        "    # Initialize previous DC coefficient to 0\n",
        "    previous_dc = 0\n",
        "    idx = 0\n",
        "    dequantized_blocks = []\n",
        "    inverse_dct = []\n",
        "\n",
        "    # Decompress each block\n",
        "    for i in range(0, padded_height, block_size):\n",
        "        for j in range(0, padded_width, block_size):\n",
        "            dc_encoded, ac_encoded = compressed_blocks[idx]\n",
        "\n",
        "            # Decode DC coefficient\n",
        "            dc_diff = huffman_decode(dc_encoded, dc_huffman_table)[0]\n",
        "            dc_coeff = previous_dc + dc_diff\n",
        "            previous_dc = dc_coeff\n",
        "\n",
        "            # Decode AC coefficients\n",
        "            ac_decoded = []\n",
        "            trailing_zeros = 0\n",
        "            for run_length, value in ac_encoded:\n",
        "                if value == -1:\n",
        "                    trailing_zeros = run_length\n",
        "                    break\n",
        "                else:\n",
        "                    zeros = [0] * run_length\n",
        "                    decoded_value = huffman_decode(value, ac_huffman_table)[0]\n",
        "                    ac_decoded.extend(zeros + [decoded_value])\n",
        "\n",
        "            # Pad decoded AC coefficients with zeros if necessary and add trailing zeros\n",
        "            ac_decoded.extend([0] * (63 - len(ac_decoded)))\n",
        "            ac_decoded.extend([0] * trailing_zeros)\n",
        "\n",
        "            # Insert DC coefficient at the beginning of ac_decoded\n",
        "            ac_decoded.insert(0, dc_coeff)\n",
        "\n",
        "            # Reconstruct the 8x8 block using inverse zigzag\n",
        "            quantized_block = inverse_zigzag_order(ac_decoded, block_size=8)\n",
        "\n",
        "            # Dequantize the block\n",
        "            dct_block = dequantize_block(quantized_block, adjusted_matrix)\n",
        "            dequantized_blocks.append(dct_block)\n",
        "\n",
        "            # Apply inverse DCT\n",
        "            decompressed_block = compute_idct(dct_block)\n",
        "            inverse_dct.append(decompressed_block)\n",
        "\n",
        "            # Clip pixel values to valid range and assign to decompressed image\n",
        "            decompressed_image[i:i + 8, j:j + 8] = np.clip(decompressed_block, 0, 255)\n",
        "            idx += 1\n",
        "\n",
        "    # Crop the decompressed image to its original size\n",
        "    cropped_image = decompressed_image[:original_height, :original_width]\n",
        "    return cropped_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Showtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "K8CAOCJ9dtUm",
        "outputId": "ed1d6d64-e6c7-4e7c-fe6a-cc82f9e20fcb"
      },
      "outputs": [],
      "source": [
        "def calculate_rmse(original_image, decompressed_image):\n",
        "    \"\"\"Calculates the RMSE between two images.\"\"\"\n",
        "    return np.sqrt(np.mean((original_image - decompressed_image)**2))\n",
        "\n",
        "def calculate_bpp(compressed_data, image_shape):\n",
        "    \"\"\"Calculates the BPP of a compressed image.\"\"\"\n",
        "    compressed_size_bits = len(compressed_data)*8 # Size in bits\n",
        "    num_pixels = image_shape[0] * image_shape[1]\n",
        "    return compressed_size_bits / num_pixels\n",
        "\n",
        "\n",
        "def analyze_images(folder_path, quality_factors, output_folder):\n",
        "    \"\"\"Simulates different quality factors and plots RMSE vs BPP, saving the plots to output_folder.\"\"\"\n",
        "    \n",
        "    min_rmse = np.inf\n",
        "    max_rmse = -np.inf\n",
        "    min_rmse_image = None\n",
        "    max_rmse_image = None\n",
        "\n",
        "    for quality_factor in quality_factors:\n",
        "        rmse_values = []\n",
        "        bpp_values = []\n",
        "        compression_rates = []\n",
        "        image_labels = []  # To track filenames for compression rate plot\n",
        "\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(('.png', '.jpg', '.jpeg', '.JPG')):  # Check for image files\n",
        "                filepath = os.path.join(folder_path, filename)\n",
        "                original_image = load_image(filepath)  # Load image using your function\n",
        "\n",
        "                # Compress and decompress the image\n",
        "                compressed_data, _, _ = compress_image(filepath, quality_factor)\n",
        "                decompressed_image = decompress_image(compressed_data)\n",
        "\n",
        "                # Calculate RMSE and BPP\n",
        "                rmse = calculate_rmse(original_image, decompressed_image)\n",
        "                bpp = calculate_bpp(compressed_data, original_image.shape)\n",
        "                original_size = original_image.nbytes  # Get original file size in bytes\n",
        "                compressed_size = len(compressed_data)\n",
        "                compression_rate = original_size / compressed_size\n",
        "\n",
        "                # Store the values\n",
        "                rmse_values.append(rmse)\n",
        "                bpp_values.append(bpp)\n",
        "                compression_rates.append(compression_rate)\n",
        "                image_labels.append(filename)\n",
        "\n",
        "                # Save the comparison image\n",
        "                comparison_image_path = os.path.join(output_folder, f\"comparison_quality_{quality_factor}_{filename}\")\n",
        "                # show_images(original_image, decompressed_image, quality_factor, comparison_image_path)\n",
        "\n",
        "                # Track min and max RMSE images\n",
        "                if rmse < min_rmse:\n",
        "                    min_rmse = rmse\n",
        "                    min_rmse_image = (original_image, decompressed_image, quality_factor, filename)\n",
        "                \n",
        "                if rmse > max_rmse:\n",
        "                    max_rmse = rmse\n",
        "                    max_rmse_image = (original_image, decompressed_image, quality_factor, filename)\n",
        "\n",
        "        # Save RMSE vs BPP plot for the current quality factor\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(bpp_values, rmse_values, marker='o', color='blue', label=f'Quality Factor: {quality_factor}')\n",
        "        plt.xlabel(\"BPP (Bits per Pixel)\")\n",
        "        plt.ylabel(\"RMSE (Root Mean Squared Error)\")\n",
        "        plt.title(f\"RMSE vs BPP (Quality Factor: {quality_factor})\")\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save the plot as an image file\n",
        "        rmse_bpp_filename = os.path.join(output_folder, f\"RMSE_vs_BPP_QF_{quality_factor}.png\")\n",
        "        plt.savefig(rmse_bpp_filename)\n",
        "        plt.close()  # Close the plot to avoid overlapping with the next one\n",
        "\n",
        "        # Save Compression Rate plot for the current quality factor\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.bar(image_labels, compression_rates, color='orange')\n",
        "        plt.xlabel(\"Image\")\n",
        "        plt.ylabel(\"Compression Rate\")\n",
        "        plt.title(f\"Compression Rate per Image (Quality Factor: {quality_factor})\")\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the plot as an image file\n",
        "        compression_rate_filename = os.path.join(output_folder, f\"Compression_Rate_QF_{quality_factor}.png\")\n",
        "        plt.savefig(compression_rate_filename)\n",
        "        plt.close()  # Close the plot to avoid overlapping with the next one\n",
        "\n",
        "        print(f\"Saved plots for Quality Factor {quality_factor} in {output_folder}\")\n",
        "\n",
        "    # Save images with minimum and maximum RMSE\n",
        "    if min_rmse_image:\n",
        "        min_image_path = os.path.join(output_folder, f\"min_rmse_image_{min_rmse:.2f}.png\")\n",
        "        show_images(min_rmse_image[0], min_rmse_image[1], min_rmse_image[2], min_image_path)\n",
        "        print(f\"Saved image with minimum RMSE ({min_rmse:.2f}) at {min_rmse_image[3]}\")\n",
        "        \n",
        "    if max_rmse_image:\n",
        "        max_image_path = os.path.join(output_folder, f\"max_rmse_image_{max_rmse:.2f}.png\")\n",
        "        show_images(max_rmse_image[0], max_rmse_image[1], max_rmse_image[2], max_image_path)\n",
        "        print(f\"Saved image with maximum RMSE ({max_rmse:.2f}) at {max_rmse_image[3]}\")\n",
        "\n",
        "# Function to show and save images\n",
        "def show_images(original_image, decompressed_image, quality_factor, save_path):\n",
        "    \"\"\"\n",
        "    Displays and saves a comparison of the original and decompressed images.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    \n",
        "    # Original image\n",
        "    axes[0].imshow(original_image, cmap='gray')\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Decompressed image\n",
        "    axes[1].imshow(decompressed_image, cmap='gray')\n",
        "    axes[1].set_title(f\"Decompressed Image (Quality Factor: {quality_factor})\")\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # Save the figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()  # Free memory\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uph_dp_5i77l"
      },
      "source": [
        "# Showtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZXX9rIz6tKNR",
        "outputId": "71499879-7bcc-4489-d898-4374e82ac1e7"
      },
      "outputs": [],
      "source": [
        "# Simulated list of quality factors\n",
        "quality_factors = [10, 50, 100]  # Simulate quality factors\n",
        "\n",
        "# Filepath of the image to process\n",
        "filepath = './dataset/urban100/img_010_SRF_2_LR.png'\n",
        "\n",
        "# Folder to save results\n",
        "save_folder = './comparison_images'\n",
        "os.makedirs(save_folder, exist_ok=True)  # Ensure the folder exists\n",
        "\n",
        "# Process the image for each quality factor\n",
        "for quality_factor in quality_factors:\n",
        "    # Load the original image\n",
        "    original_image = load_image(filepath)\n",
        "    \n",
        "    # Compress and decompress the image\n",
        "    compressed_data, _, _ = compress_image(filepath, quality_factor)\n",
        "    decompressed_image = decompress_image(compressed_data)\n",
        "    # Save the comparison image\n",
        "    save_path = os.path.join(save_folder, f\"comparison_quality_{quality_factor}.png\")\n",
        "    show_images(original_image, decompressed_image, quality_factor, save_path)\n",
        "\n",
        "analyze_images('./dataset/urban100', quality_factors,'./Results')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
