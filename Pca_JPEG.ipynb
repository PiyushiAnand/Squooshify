{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVkQpuaDh0hX"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHE6Mh0lZeZ6",
        "outputId": "5fc934d5-fe11-4b82-947d-47003cf20cca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.fftpack import dct, idct\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import heapq\n",
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "import gzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwBPBjB2iJq4"
      },
      "source": [
        "# Load the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ajvXZgY-dCVa"
      },
      "outputs": [],
      "source": [
        "def load_image(filepath):\n",
        "    image = Image.open(filepath).convert('L')\n",
        "    return np.array(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DCT and IDCT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DCT and inverse DCT for 8x8 blocks\n",
        "def compute_dct(block):\n",
        "    return dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
        "\n",
        "def compute_idct(block):\n",
        "    return idct(idct(block.T, norm='ortho').T, norm='ortho')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantization Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard JPEG quantization matrix\n",
        "quantization_matrix = np.array([\n",
        "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Huffman tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Huffman Tree generation\n",
        "def build_huffman_tree(data):\n",
        "    frequency = Counter(data)\n",
        "    heap = [[weight, [symbol, \"\"]] for symbol, weight in frequency.items()]\n",
        "    heapq.heapify(heap)\n",
        "\n",
        "    while len(heap) > 1:\n",
        "        lo = heapq.heappop(heap)\n",
        "        hi = heapq.heappop(heap)\n",
        "        for pair in lo[1:]:\n",
        "            pair[1] = '0' + pair[1]\n",
        "        for pair in hi[1:]:\n",
        "            pair[1] = '1' + pair[1]\n",
        "        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
        "\n",
        "    return {symbol: code for symbol, code in heapq.heappop(heap)[1:]}\n",
        "\n",
        "def huffman_encode(data, huffman_table):\n",
        "    return ''.join(huffman_table[val] for val in data)\n",
        "\n",
        "def huffman_decode(encoded_data, huffman_table):\n",
        "    inverse_table = {code: symbol for symbol, code in huffman_table.items()}\n",
        "    decoded_data, current_code = [], \"\"\n",
        "    for bit in encoded_data:\n",
        "        current_code += bit\n",
        "        if current_code in inverse_table:\n",
        "            decoded_data.append(inverse_table[current_code])\n",
        "            current_code = \"\"\n",
        "    return decoded_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantize the DCT block\n",
        "def quantize_block(dct_block, quant_matrix, quality_factor):\n",
        "    # Ensure quality_factor is within valid bounds\n",
        "    quality_factor = max(1, min(100, quality_factor))\n",
        "    #print(dct_block.shape)\n",
        "\n",
        "    if quality_factor < 50:\n",
        "      scale = 5000 / quality_factor\n",
        "    else:\n",
        "      scale = 200 - 2 * quality_factor\n",
        "\n",
        "    adjusted_matrix = np.floor((quantization_matrix * scale + 50) / 100)\n",
        "    adjusted_matrix[adjusted_matrix == 0] = 1\n",
        "    #print(adjusted_matrix.shape)\n",
        "    # Quantize the DCT block\n",
        "    quantized_block = np.round(dct_block / adjusted_matrix).astype(int)\n",
        "    # print(adjusted_matrix)\n",
        "    return quantized_block, adjusted_matrix\n",
        "\n",
        "def dequantize_block(quantized_block, adjusted_matrix):\n",
        "    return (quantized_block * adjusted_matrix).astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ZigZag Order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def zigzag_order(block):\n",
        "    rows, cols = block.shape\n",
        "    solution = [[] for i in range(rows + cols - 1)]\n",
        "\n",
        "    for row in range(rows):\n",
        "        for col in range(cols):\n",
        "            sum = row + col\n",
        "            if(sum % 2 == 0):\n",
        "                #add at beginning\n",
        "                solution[sum].insert(0, block[row][col])\n",
        "            else:\n",
        "                #add at end of the list\n",
        "                solution[sum].append(block[row][col])\n",
        "\n",
        "    return np.array([item for sublist in solution for item in sublist])\n",
        "def inverse_zigzag_order(zigzag_values, block_size=8):\n",
        "    matrix = np.zeros((block_size, block_size), dtype=int)\n",
        "    index = 0\n",
        "\n",
        "    for i in range(block_size + block_size - 1):\n",
        "        if i % 2 == 0:  # Even diagonal (up-right)\n",
        "            # Moving up-right with decrementing row and incrementing column\n",
        "            for j in range(min(i + 1, block_size)):\n",
        "                row = i - j\n",
        "                col = j\n",
        "                if row >= 0 and row < block_size and col >= 0 and col < block_size:  # Check matrix boundaries\n",
        "                    matrix[row, col] = zigzag_values[index]\n",
        "                    index += 1\n",
        "        else:  # Odd diagonal (down-left)\n",
        "            # Moving down-left with incrementing row and decrementing column\n",
        "            for j in range(min(i + 1, block_size)):\n",
        "                col = i - j\n",
        "                row = j\n",
        "                if row >= 0 and row < block_size and col >= 0 and col < block_size:\n",
        "                    matrix[row, col] = zigzag_values[index]\n",
        "                    index += 1\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_length_encoding(zigzag_values,huffman_table):\n",
        "    encoded_values = []\n",
        "    run_length = 0\n",
        "\n",
        "    for value in zigzag_values:\n",
        "        if value == 0:\n",
        "            run_length += 1\n",
        "        else:\n",
        "            encoded_values.append((np.uint8(run_length),huffman_table[value]))  # Store run-length, size, and value\n",
        "            run_length = 0  # Reset run-length\n",
        "\n",
        "    # Store trailing zeros count in the EOB marker:\n",
        "    encoded_values.append((np.uint8(run_length),-1))  # EOB with trailing zeros count\n",
        "    # encoded_values.append((0, 0, 'EOB'))\n",
        "    return encoded_values\n",
        "\n",
        "def run_length_decoding(encoded_values):\n",
        "    decoded_values = []\n",
        "    trailing_zeros_count = 0  # Initialize trailing zeros count\n",
        "\n",
        "    for run_length , value in encoded_values:\n",
        "        if value == -1:  # Check for EOB marker\n",
        "            trailing_zeros_count = value  # Get trailing zeros count from EOB\n",
        "            break  # Stop decoding at the EOB marker\n",
        "        else:\n",
        "            decoded_values.extend([0] * run_length)  # Add zeros for the run-length\n",
        "            decoded_values.append(value)  # Append the actual value\n",
        "\n",
        "    # Add trailing zeros (if any) after decoding:\n",
        "    decoded_values.extend([0] * trailing_zeros_count)\n",
        "\n",
        "    return decoded_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Padding image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_image(image, block_size=8):\n",
        "    \"\"\"Pad the image to make its dimensions a multiple of block_size.\"\"\"\n",
        "    height, width = image.shape\n",
        "    pad_height = (block_size - (height % block_size)) % block_size\n",
        "    pad_width = (block_size - (width % block_size)) % block_size\n",
        "    padded_image = np.pad(image, ((0, pad_height), (0, pad_width)), mode='constant')\n",
        "    return padded_image, height, width"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mhX2UDMivp1"
      },
      "source": [
        "# Compress Image PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LdJKgZBaddNa"
      },
      "outputs": [],
      "source": [
        "def pca_compress(image, num_components):\n",
        "    # Center the image matrix\n",
        "    mean_image = np.mean(image, axis=0)\n",
        "    centered_image = image - mean_image\n",
        "\n",
        "    # Compute the covariance matrix\n",
        "    covariance_matrix = np.cov(centered_image, rowvar=False)\n",
        "\n",
        "    # Eigen decomposition\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
        "\n",
        "    # Sort eigenvalues and eigenvectors in descending order\n",
        "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvalues = eigenvalues[sorted_indices]\n",
        "    eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "    # Select top principal components\n",
        "    selected_eigenvectors = eigenvectors[:, :num_components]\n",
        "\n",
        "    # Project image onto the selected principal components\n",
        "    compressed_image = np.dot(centered_image, selected_eigenvectors)\n",
        "\n",
        "    return compressed_image, mean_image, selected_eigenvectors\n",
        "\n",
        "# Compress image using PCA\n",
        "def compress_image_pca(filepath, num_components):\n",
        "    image = load_image(filepath)\n",
        "    compressed_image, mean_image, selected_eigenvectors = pca_compress(image, num_components)\n",
        "\n",
        "    # Save compressed data\n",
        "    compressed_data = {\n",
        "        'compressed_image': compressed_image,\n",
        "        'mean_image': mean_image,\n",
        "        'eigenvectors': selected_eigenvectors\n",
        "    }\n",
        "    compressed_stream = BytesIO()\n",
        "    with gzip.GzipFile(fileobj=compressed_stream, mode='wb') as gzip_file:\n",
        "        pickle.dump(compressed_data, gzip_file)\n",
        "\n",
        "    return compressed_stream.getvalue()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOvjKt1diz69"
      },
      "source": [
        "# Decompress Image PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rJyv-j0HdhB_"
      },
      "outputs": [],
      "source": [
        "def pca_decompress(compressed_image, mean_image, selected_eigenvectors):\n",
        "    # Reconstruct the image from principal components\n",
        "    reconstructed_image = np.dot(compressed_image, selected_eigenvectors.T) + mean_image\n",
        "    return reconstructed_image\n",
        "\n",
        "# Decompress image using PCA\n",
        "def decompress_image_pca(compressed_data):\n",
        "    \"\"\"Decompresses PCA-compressed image data and reconstructs the image.\"\"\"\n",
        "    compressed_stream = BytesIO(compressed_data)\n",
        "    # Decompress the data using gzip and load it using pickle\n",
        "    with gzip.GzipFile(fileobj=compressed_stream, mode='rb') as gzip_file:\n",
        "        decompressed_data = pickle.load(gzip_file)\n",
        "    # Extract the decompressed components\n",
        "    decompressed_image = decompressed_data['compressed_image']\n",
        "    mean_image = decompressed_data['mean_image']\n",
        "    selected_eigenvectors = decompressed_data['eigenvectors']\n",
        "    # Reconstruct the image from the PCA components\n",
        "    reconstructed_image = pca_decompress(decompressed_image, mean_image, selected_eigenvectors)\n",
        "    # Ensure pixel values are within valid range (0-255) and return as uint8\n",
        "    return np.clip(reconstructed_image, 0, 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compress Image JPEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BzQASX4Q-3L3"
      },
      "outputs": [],
      "source": [
        "def compress_image(filepath, quality_factor):\n",
        "    image = load_image(filepath)\n",
        "    height, width = image.shape\n",
        "    compressed_data = []\n",
        "    dc_diff_values = []\n",
        "    ac_values = []\n",
        "\n",
        "    adjusted_matrix = None\n",
        "    quantized_blocks = []\n",
        "    dct_blocks = []\n",
        "\n",
        "    #pad the image so that both row and column are nearest multiple 8\n",
        "    padded_image, original_height, original_width = pad_image(image, 8)\n",
        "    padded_height, padded_width = padded_image.shape\n",
        "    \n",
        "    # Divide into 8x8 blocks, apply DCT and quantize\n",
        "    previous_dc = 0\n",
        "    #store the orignal size of image as well\n",
        "    for i in range(0, padded_height, 8):\n",
        "        for j in range(0, padded_width, 8):\n",
        "            dct_blocks.append(padded_image[i:i+8, j:j+8])\n",
        "            block = padded_image[i:i+8, j:j+8]\n",
        "            dct_block = compute_dct(block)\n",
        "   \n",
        "            quantized_block, adjusted_matrix = quantize_block(dct_block, quantization_matrix, quality_factor)\n",
        "            quantized_blocks.append(quantized_block)\n",
        "\n",
        "            # DC and AC separation\n",
        "            dc_diff = quantized_block[0, 0] - previous_dc\n",
        "            previous_dc = quantized_block[0, 0]\n",
        "            dc_diff_values.append(dc_diff)\n",
        "            ac_values.extend(zigzag_order(quantized_block)[1:])\n",
        "\n",
        "    # Build Huffman trees\n",
        "    dc_huffman_table = build_huffman_tree(dc_diff_values)\n",
        "    ac_huffman_table = build_huffman_tree([val for val in ac_values if val != 0])\n",
        "   \n",
        "    # Compress each block\n",
        "    previous_dc = 0\n",
        "    for i in range(0, padded_height, 8):\n",
        "        for j in range(0, padded_width, 8):\n",
        "            block = padded_image[i:i+8, j:j+8]\n",
        "            dct_block = compute_dct(block)\n",
        "            quantized_block, adjusted_matrix = quantize_block(dct_block, quantization_matrix, quality_factor)\n",
        "\n",
        "            # Encode DC\n",
        "            dc_diff = quantized_block[0, 0] - previous_dc\n",
        "            previous_dc = quantized_block[0, 0]\n",
        "            dc_encoded = dc_huffman_table[dc_diff]\n",
        "\n",
        "            # Encode AC with run-length, size, and Huffman code\n",
        "            zigzag_ac = zigzag_order(quantized_block)[1:]\n",
        "            ac_encoded = run_length_encoding(zigzag_ac,ac_huffman_table)\n",
        "            compressed_data.append((dc_encoded, ac_encoded))\n",
        "\n",
        "    header = {\n",
        "        'file_size': (height, width),\n",
        "        'dc_huffman_table': dc_huffman_table,\n",
        "        'ac_huffman_table': ac_huffman_table,\n",
        "        'adjusted_matrix': adjusted_matrix\n",
        "    }\n",
        "\n",
        "    compressed_stream = BytesIO()\n",
        "    with gzip.GzipFile(fileobj=compressed_stream, mode='wb') as f:\n",
        "        pickle.dump(header, f)\n",
        "        pickle.dump(compressed_data, f)\n",
        "\n",
        "    return compressed_stream.getvalue(), dc_huffman_table, ac_huffman_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decompress Image JPEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decompress_image(compressed_data):\n",
        "\n",
        "    compressed_stream = BytesIO(compressed_data)\n",
        "\n",
        "    # Open the gzip file in read mode\n",
        "    with gzip.GzipFile(fileobj=compressed_stream, mode='rb') as f:\n",
        "        # Load the header and compressed data from the stream\n",
        "        header = pickle.load(f)\n",
        "        compressed_blocks = pickle.load(f)\n",
        "    \n",
        "    # Extract header information\n",
        "    original_height, original_width = header['file_size']  # Extract original dimensions\n",
        "    dc_huffman_table = header['dc_huffman_table']\n",
        "    ac_huffman_table = header['ac_huffman_table']\n",
        "    adjusted_matrix = header['adjusted_matrix']\n",
        "    \n",
        "    # Initialize decompressed image with padded size\n",
        "    blocks_per_row = int(np.sqrt(len(compressed_blocks)))  \n",
        "    block_size = 8\n",
        "    decompressed_image = np.zeros((original_height, original_width), dtype=np.uint8)\n",
        "    decompressed_image = pad_image(decompressed_image, block_size)[0]\n",
        "    padded_height, padded_width = decompressed_image.shape\n",
        "\n",
        "    # Initialize previous DC coefficient to 0\n",
        "    previous_dc = 0\n",
        "    idx = 0\n",
        "    dequantized_blocks = []\n",
        "    inverse_dct = []\n",
        "\n",
        "    # Decompress each block\n",
        "    for i in range(0, padded_height, block_size):\n",
        "        for j in range(0, padded_width, block_size):\n",
        "            dc_encoded, ac_encoded = compressed_blocks[idx]\n",
        "\n",
        "            # Decode DC coefficient\n",
        "            dc_diff = huffman_decode(dc_encoded, dc_huffman_table)[0]\n",
        "            dc_coeff = previous_dc + dc_diff\n",
        "            previous_dc = dc_coeff\n",
        "\n",
        "            # Decode AC coefficients\n",
        "            ac_decoded = []\n",
        "            trailing_zeros = 0\n",
        "            for run_length, value in ac_encoded:\n",
        "                if value == -1:\n",
        "                    trailing_zeros = run_length\n",
        "                    break\n",
        "                else:\n",
        "                    zeros = [0] * run_length\n",
        "                    decoded_value = huffman_decode(value, ac_huffman_table)[0]\n",
        "                    ac_decoded.extend(zeros + [decoded_value])\n",
        "\n",
        "            # Pad decoded AC coefficients with zeros if necessary and add trailing zeros\n",
        "            ac_decoded.extend([0] * (63 - len(ac_decoded)))\n",
        "            ac_decoded.extend([0] * trailing_zeros)\n",
        "\n",
        "            # Insert DC coefficient at the beginning of ac_decoded\n",
        "            ac_decoded.insert(0, dc_coeff)\n",
        "\n",
        "            # Reconstruct the 8x8 block using inverse zigzag\n",
        "            quantized_block = inverse_zigzag_order(ac_decoded, block_size=8)\n",
        "\n",
        "            # Dequantize the block\n",
        "            dct_block = dequantize_block(quantized_block, adjusted_matrix)\n",
        "            dequantized_blocks.append(dct_block)\n",
        "\n",
        "            # Apply inverse DCT\n",
        "            decompressed_block = compute_idct(dct_block)\n",
        "            inverse_dct.append(decompressed_block)\n",
        "\n",
        "            # Clip pixel values to valid range and assign to decompressed image\n",
        "            decompressed_image[i:i + 8, j:j + 8] = np.clip(decompressed_block, 0, 255)\n",
        "            idx += 1\n",
        "\n",
        "    # Crop the decompressed image to its original size\n",
        "    cropped_image = decompressed_image[:original_height, :original_width]\n",
        "\n",
        "    # Save intermediate results for debugging\n",
        "    with open('dequantized_dct.txt', 'w') as f:\n",
        "        for block in dequantized_blocks:\n",
        "            np.savetxt(f, block, fmt='%d', header=\"Block:\")\n",
        "    with open('inverse_dct.txt', 'w') as f:\n",
        "        for block in inverse_dct:\n",
        "            np.savetxt(f, block, fmt='%d', header=\"Block:\")\n",
        "\n",
        "    return cropped_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Show Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "K8CAOCJ9dtUm",
        "outputId": "304e289b-0f72-4012-86b4-b602425edc38"
      },
      "outputs": [],
      "source": [
        " # Display Images\n",
        "def show_images(original_image, decompressed_image, decompressed_pca, save_path):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Create 3 axes for 3 images\n",
        "    axes[0].imshow(original_image, cmap='gray')\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[1].imshow(decompressed_image, cmap='gray')\n",
        "    axes[1].set_title(\"Compressed Image (JPEG)\")\n",
        "    axes[2].imshow(decompressed_pca, cmap='gray')\n",
        "    axes[2].set_title(\"Compressed Image (PCA)\")\n",
        "\n",
        "    # Remove axis ticks for better image viewing\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Save the figure to a file\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()  # Close the figure to free memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate RMSE between two images\n",
        "def calculate_rmse(original_image, decompressed_image):\n",
        "    \"\"\"Calculates the RMSE between two images.\"\"\"\n",
        "    return np.sqrt(np.mean((original_image - decompressed_image) ** 2))\n",
        "\n",
        "# Calculate BPP (Bits per Pixel)\n",
        "def calculate_bpp(compressed_data, image_shape):\n",
        "    \"\"\"Calculates the BPP of a compressed image.\"\"\"\n",
        "    compressed_size_bits = len(compressed_data) * 8  # Size in bits\n",
        "    num_pixels = image_shape[0] * image_shape[1]\n",
        "    return compressed_size_bits / num_pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_all(folder_path, quality_factor, save_base_folder):\n",
        "    print(f\"\\nProcessing folder: {folder_path}\")\n",
        "    dataset_name = os.path.basename(folder_path.strip('/'))  # Extract dataset name (e.g., 'chair')\n",
        "    \n",
        "    # Create a folder for saving comparison images if it doesn't exist\n",
        "    save_folder = os.path.join(save_base_folder, dataset_name)\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    \n",
        "    # For plotting RMSE vs BPP and Compression Rate for both PCA and JPEG\n",
        "    rmse_values_jpeg = []\n",
        "    bpp_values_jpeg = []\n",
        "    rmse_values_pca = []\n",
        "    bpp_values_pca = []\n",
        "    compression_rates_jpeg = []\n",
        "    compression_rates_pca = []\n",
        "    image_labels = []  # To track filenames for compression rate plot\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            \n",
        "            try:\n",
        "                # Load original image\n",
        "                original_image = load_image(filepath)\n",
        "                \n",
        "                # Compress and decompress image (JPEG compression)\n",
        "                compressed_data_jpeg, dc_huffman_table, ac_huffman_table = compress_image(filepath, quality_factor)\n",
        "                decompressed_image_jpeg = decompress_image(compressed_data_jpeg)\n",
        "                \n",
        "                # Compress and decompress image (PCA-based compression)\n",
        "                compressed_data_pca = compress_image_pca(filepath, quality_factor)\n",
        "                decompressed_image_pca = decompress_image_pca(compressed_data_pca)  # Use compressed_data_pca\n",
        "                \n",
        "                # Calculate RMSE and BPP for JPEG\n",
        "                rmse_jpeg = calculate_rmse(original_image, decompressed_image_jpeg)\n",
        "                bpp_jpeg = calculate_bpp(compressed_data_jpeg, original_image.shape)\n",
        "                \n",
        "                # Calculate RMSE and BPP for PCA\n",
        "                rmse_pca = calculate_rmse(original_image, decompressed_image_pca)\n",
        "                bpp_pca = calculate_bpp(compressed_data_pca, original_image.shape)\n",
        "                \n",
        "                # Calculate compression rate (original vs. compressed size)\n",
        "                original_size = original_image.nbytes  # Get original file size in bytes\n",
        "                \n",
        "                # For JPEG\n",
        "                compressed_size_jpeg = len(compressed_data_jpeg)  # Get the compressed data size for JPEG\n",
        "                compression_rate_jpeg = original_size / compressed_size_jpeg\n",
        "                \n",
        "                # For PCA\n",
        "                compressed_size_pca = len(compressed_data_pca)  # Get the compressed data size for PCA\n",
        "                compression_rate_pca = original_size / compressed_size_pca\n",
        "\n",
        "                # Store RMSE, BPP, and compression rates for both JPEG and PCA\n",
        "                rmse_values_jpeg.append(rmse_jpeg)\n",
        "                bpp_values_jpeg.append(bpp_jpeg)\n",
        "                compression_rates_jpeg.append(compression_rate_jpeg)\n",
        "                \n",
        "                rmse_values_pca.append(rmse_pca)\n",
        "                bpp_values_pca.append(bpp_pca)\n",
        "                compression_rates_pca.append(compression_rate_pca)\n",
        "                \n",
        "                image_labels.append(filename)\n",
        "                \n",
        "                # Generate a unique output file path based on the folder and image name\n",
        "                output_filename = f\"{os.path.splitext(filename)[0]}_comparison+{quality_factor}.png\"\n",
        "                output_path = os.path.join(save_folder, output_filename)\n",
        "                \n",
        "                # Visualize and save the images\n",
        "                show_images(original_image, decompressed_image_jpeg, decompressed_image_pca, output_path)\n",
        "                \n",
        "                print(f\"Saved comparison for {filename} as {output_filename}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "    \n",
        "    # After processing all images in the folder, generate RMSE vs BPP plots for both PCA and JPEG\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(bpp_values_jpeg, rmse_values_jpeg, marker='o', color='blue', label=f'JPEG (Quality Factor: {quality_factor})')\n",
        "    plt.scatter(bpp_values_pca, rmse_values_pca, marker='x', color='red', label=f'PCA (Quality Factor: {quality_factor})')\n",
        "    plt.xlabel(\"BPP (Bits per Pixel)\")\n",
        "    plt.ylabel(\"RMSE (Root Mean Squared Error)\")\n",
        "    plt.title(f\"RMSE vs BPP (JPEG vs PCA) - Quality Factor: {quality_factor}\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_folder, f\"rmse_vs_bpp_{quality_factor}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Generate Compression Rate plots for both JPEG and PCA\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(image_labels, compression_rates_jpeg, color='blue', label='JPEG')\n",
        "    plt.bar(image_labels, compression_rates_pca, color='red', alpha=0.5, label='PCA')\n",
        "    plt.xlabel(\"Image\")\n",
        "    plt.ylabel(\"Compression Rate\")\n",
        "    plt.title(f\"Compression Rate per Image (JPEG vs PCA) - Quality Factor: {quality_factor}\")\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_folder, f\"compression_rate_{quality_factor}.png\"))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of folders to process\n",
        "all_folders = ['./dataset/chair/', './dataset/Faces', './dataset/kangaroo', './dataset/Motorbikes', './dataset/pizza']\n",
        "save_base_folder = './comparisons'  # Base folder to save comparison results\n",
        "\n",
        "# Iterate through each folder and apply the function\n",
        "for folder in all_folders:\n",
        "    compare_all(folder, 100, save_base_folder)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
